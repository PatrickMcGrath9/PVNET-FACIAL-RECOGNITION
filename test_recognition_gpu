import face_recognition
import cv2
import numpy as np
import pickle
import pyttsx3
import time
import threading
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from apscheduler.schedulers.background import BackgroundScheduler

# Parameters
frame_skip = 3
frame_count = 0
scaling_factor = 1.25  # Scale down for faster processing
database_path = "C:/Users/Educa/Documents/GitHub/PVNET-FACIAL-RECOGNITION/Database"
encoding_file = "encodings.pkl"

# Global flag for pausing recognition
pause_recognition = False

# Load known faces and encodings
def load_encodings():
    if os.path.exists(encoding_file):
        with open(encoding_file, "rb") as f:
            return pickle.load(f)
    return [], [], set()

known_face_encodings, known_face_names, processed_images = load_encodings()

# Initialize TTS engine
engine = pyttsx3.init()
last_spoken_time = {}
face_detection_time = {}
SPEAK_INTERVAL = 3600  # 1 hour
DETECTION_TIME_REQUIRED = 0.5

# Initialize webcam
video_capture = cv2.VideoCapture(0)
video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

def speak_name(name):
    """Threaded function to speak a person's name."""
    engine.say(f"Hello {name}")
    engine.runAndWait()

def detect_faces(frame):
    """Detect faces in a frame."""
    return face_recognition.face_locations(frame, model="hog")

def encode_face(frame, face_location):
    """Encode a single face."""
    return face_recognition.face_encodings(frame, [face_location])[0]

def daily_encoding_update():
    """Function to update encodings daily by adding new images."""
    global known_face_encodings, known_face_names, processed_images, pause_recognition

    print("Starting daily encoding update...")
    pause_recognition = True  # Pause facial recognition

    encoded_count = len(processed_images)
    
    # Loop over each person in the database
    for person_name in os.listdir(database_path):
        person_folder = os.path.join(database_path, person_name)
        
        if os.path.isdir(person_folder):
            for image_name in os.listdir(person_folder):
                if image_name.endswith(('.jpg', '.jpeg', '.png')):
                    image_path = os.path.join(person_folder, image_name)
                    relative_image_path = os.path.relpath(image_path, database_path)
                    
                    print(f"Checking {relative_image_path}...")  # Debugging print
                    if relative_image_path in processed_images:
                        print(f"Already processed: {relative_image_path}")  # Debugging print
                        continue
                    
                    print(f"Processing new image: {relative_image_path}")  # Debugging print
                    image = face_recognition.load_image_file(image_path)
                    face_encodings = face_recognition.face_encodings(image)

                    # Check if any face encodings were found
                    if face_encodings:
                        print(f"Face detected in {relative_image_path}")  # Debugging print
                        known_face_encodings.append(face_encodings[0])
                        known_face_names.append(person_name)
                        processed_images.add(relative_image_path)
                        encoded_count += 1
                    else:
                        print(f"No face encodings found for {relative_image_path}")  # Debugging print

    # Save updated encodings to file
    with open(encoding_file, "wb") as f:
        pickle.dump((known_face_encodings, known_face_names, processed_images), f)
    print(f"Daily encoding update completed. {encoded_count} new images processed.")

    pause_recognition = False  # Resume facial recognition

def check_encodings():
    """Check the current encodings in the file."""
    if os.path.exists(encoding_file):
        with open(encoding_file, "rb") as f:
            known_face_encodings, known_face_names, processed_images = pickle.load(f)
            print(f"Loaded {len(known_face_encodings)} encodings and {len(known_face_names)} names.")

# Schedule daily encoding update at 1 PM
scheduler = BackgroundScheduler()
scheduler.add_job(daily_encoding_update, 'cron', hour=13)  # Adjust hour to 13 for 1 PM
scheduler.start()

# Manually trigger the encoding update for testing
daily_encoding_update()
check_encodings()  # Check current encodings after update

# Main loop for continuous recognition
executor = ThreadPoolExecutor()
try:
    while True:
        if pause_recognition:
            continue  # Skip frame processing if recognition is paused

        ret, frame = video_capture.read()
        if not ret:
            print("Failed to grab frame. Exiting...")
            break

        frame_count += 1
        if frame_count % frame_skip != 0:
            continue

        # Resize frame for faster processing
        small_frame = cv2.resize(frame, (0, 0), fx=scaling_factor, fy=scaling_factor)
        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

        # Detect faces
        detection_future = executor.submit(detect_faces, rgb_small_frame)
        face_locations = detection_future.result()

        face_encodings = []
        face_names = []

        if face_locations:
            # Encode faces in parallel
            encoding_executor = ThreadPoolExecutor(max_workers=min(10, len(face_locations)))
            encoding_futures = {encoding_executor.submit(encode_face, rgb_small_frame, loc): loc for loc in face_locations}

            # Retrieve encoding results
            for future in as_completed(encoding_futures):
                try:
                    face_encoding = future.result()  # Get the result from each future
                    face_encodings.append(face_encoding)
                except IndexError:
                    print("No face encoding found for one of the detected faces.")
                except Exception as e:
                    print(f"An error occurred during encoding: {e}")

            encoding_executor.shutdown(wait=True)

            # Identify faces
            for face_encoding in face_encodings:
                matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.5)
                name = "Unknown"

                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
                best_match_index = np.argmin(face_distances) if matches else None
                if best_match_index is not None and matches[best_match_index]:
                    name = known_face_names[best_match_index]

                # Track and speak names
                current_time = time.time()
                if name not in face_detection_time:
                    face_detection_time[name] = current_time

                if current_time - face_detection_time[name] >= DETECTION_TIME_REQUIRED:
                    if name not in last_spoken_time or (current_time - last_spoken_time[name]) > SPEAK_INTERVAL:
                        threading.Thread(target=speak_name, args=(name,)).start()
                        last_spoken_time[name] = current_time

                face_names.append(name)

            # Remove old entries
            for name in list(face_detection_time.keys()):
                if name not in face_names:
                    del face_detection_time[name]

        # Display the results
        for (top, right, bottom, left), name in zip(face_locations, face_names):
            top = int(top / scaling_factor)
            right = int(right / scaling_factor)
            bottom = int(bottom / scaling_factor)
            left = int(left / scaling_factor)

            # Draw the bounding box and name
            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)
            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)
            font_scale = (bottom - top) / 150
            cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, font_scale, (255, 255, 255), 1)

        cv2.imshow('Video', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

finally:
    video_capture.release()
    cv2.destroyAllWindows()
    executor.shutdown()
    scheduler.shutdown()
